DATALOADER:
  TRAIN_X:
    BATCH_SIZE: 1
  TEST:
    BATCH_SIZE: 100
  NUM_WORKERS: 8

INPUT:
  SIZE: (224, 224)
  INTERPOLATION: "bicubic"
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  TRANSFORMS: ["random_resized_crop", "random_flip", "normalize"]

OPTIM_LORA:
  NAME: "adamw"
  LR: 2e-4
  MAX_EPOCH: 10
  LR_SCHEDULER: "cosine"
  WARMUP_EPOCH: 1
  WARMUP_TYPE: "constant"
  WARMUP_CONS_LR: 1e-5
  WARMUP_MIN_LR: 1e-6  # linear warmup에서 사용
  WARMUP_RECOUNT: false  # warmup 기간을 재계산 여부
  WEIGHT_DECAY: 0.01  # 추가
  MOMENTUM: 0.9  # 추가
  SGD_DAMPNING: 0
  SGD_NESTEROV: false
  RMSPROP_ALPHA: 0.99
  STAGED_LR: false
  NEW_LAYERS: []
  BASE_LR_MULT: 1.0
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  STEPSIZE: 10  # 추가: StepLR과 같은 스케줄러에서 필요
  GAMMA: 0.1  # 추가: 학습률 감소 비율


OPTIM_PROMPTLEARNER:
  NAME: "sgd"
  LR: 0.002
  MAX_EPOCH: 10
  LR_SCHEDULER: "cosine"
  WARMUP_EPOCH: 1
  WARMUP_TYPE: "constant"
  WARMUP_CONS_LR: 1e-5
  WARMUP_MIN_LR: 1e-6
  WARMUP_RECOUNT: true
  WEIGHT_DECAY: 0.01  # 추가
  MOMENTUM: 0.9  # 추가
  SGD_DAMPNING: 0
  SGD_NESTEROV: false
  RMSPROP_ALPHA: 0.99
  STAGED_LR: false
  NEW_LAYERS: []
  BASE_LR_MULT: 1.0
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  STEPSIZE: 10  # 추가: StepLR과 같은 스케줄러에서 필요
  GAMMA: 0.1  # 추가: 학습률 감소 비율


TRAIN:
  PRINT_FREQ: 20

MODEL:
  BACKBONE:
    NAME: "ViT-B/16"

TRAINER:
  LORA_PROMPTOTYPE:
    N_CTX: 4
    CTX_INIT: "a photo of a"
    CTX_MID: ", which is a"
    PREC: "amp"
    POSITION: "all"
    ENCODER: "both"
    PARAMS: ["q","k","v"]
    RANK: 2
    ALPHA: 1
    DROPOUT_RATE: 0.25